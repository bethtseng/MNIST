{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST\n",
    "Learn computer vision fundamentals with the famous MNIST data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import DataFrame, Series, crosstab\n",
    "from datetime import datetime, timedelta \n",
    "from collections import Counter\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "matplotlib.style.use('ggplot')\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/train.csv')\n",
    "test= pd.read_csv(\"data/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('training-set shape: ({0[0]},{0[1]})'.format(train.shape))\n",
    "train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('testing-set shape: ({0[0]},{0[1]})'.format(test.shape))\n",
    "test.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = train['label']\n",
    "train = train.drop(\"label\",axis=1)\n",
    "\n",
    "labels_count = np.unique(labels.values)\n",
    "labels_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display(img):\n",
    "    \n",
    "    image_size = img.shape[0]\n",
    "    image_width = image_height = np.ceil(np.sqrt(image_size)).astype(np.uint8)\n",
    "    \n",
    "    # (784) => (28,28)\n",
    "    one_image = img.reshape(image_width,image_height)\n",
    "    \n",
    "    plt.axis('off')\n",
    "    plt.imshow(one_image, cmap='Greys_r')\n",
    "\n",
    "for i in range(10):\n",
    "    plt.subplot(1,10,i+1)\n",
    "    display(train.values[i])\n",
    "plt.show()\n",
    "print('label: %s' % (labels.values[0:10],))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert class labels from scalars to one-hot vectors\n",
    "# 0 => [1 0 0 0 0 0 0 0 0 0]\n",
    "# 1 => [0 1 0 0 0 0 0 0 0 0]\n",
    "# ...\n",
    "# 9 => [0 0 0 0 0 0 0 0 0 1]\n",
    "def dense_to_one_hot(target, num_classes):\n",
    "    one_hot_targets = np.eye(num_classes)[target]\n",
    "    return one_hot_targets\n",
    "\n",
    "labels = dense_to_one_hot(labels.values, len(labels_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "### Logistic regression as baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "learning_rate = 0.001\n",
    "training_epochs = 30\n",
    "batch_size = 64\n",
    "display_step = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf Graph Input\n",
    "x = tf.placeholder(tf.float32, [None, 784]) # mnist data image of shape 28*28=784\n",
    "y = tf.placeholder(tf.float32, [None, 10]) # 0-9 digits recognition => 10 classes\n",
    "\n",
    "# Set model weights\n",
    "W = tf.Variable(tf.zeros([784, 10]))    # tf.random_normal()\n",
    "#W = tf.random_normal([784, 10])/1000    # tf.random_normal()\n",
    "b = tf.Variable(tf.zeros([10]))\n",
    "\n",
    "# Construct model\n",
    "pred = tf.nn.softmax(tf.matmul(x, W) + b) # Softmax\n",
    "\n",
    "# Minimize error using cross entropy\n",
    "cost = tf.losses.sigmoid_cross_entropy(y, pred)\n",
    "# Gradient Descent\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)\n",
    "\n",
    "# Initialize the variables (i.e. assign their default value)\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(data, batch_size=64):\n",
    "    l = len(data)\n",
    "    arr = np.arange(l)\n",
    "    #np.random.shuffle(arr)\n",
    "    for ndx in range(0, l, batch_size):\n",
    "        select = arr[ndx:min(ndx + batch_size, l)]\n",
    "        yield data[select]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start training\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    # Training cycle\n",
    "    for epoch in range(training_epochs):\n",
    "        avg_cost = counter = 0.\n",
    "        \n",
    "        train_X_batch = get_batch(train.values, batch_size)\n",
    "        train_Y_batch = get_batch(labels, batch_size)\n",
    "        for batch_xs, batch_ys in zip(train_X_batch, train_Y_batch):\n",
    "\n",
    "            # Fit training using batch data\n",
    "            _, c = sess.run([optimizer, cost], feed_dict={x: batch_xs, y: batch_ys})\n",
    "\n",
    "            # Compute average loss\n",
    "            avg_cost += c\n",
    "            counter += 1\n",
    "        avg_cost /= counter\n",
    "        \n",
    "        # Display logs per epoch step\n",
    "        if (epoch+1) % display_step == 0:\n",
    "            print(\"Epoch:\", '%04d' % (epoch+1), \"cost=\", \"{:.9f}\".format(avg_cost))\n",
    "\n",
    "    print(\"Optimization Finished!\")\n",
    "\n",
    "    # Test model\n",
    "    correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "    # Calculate accuracy for 3000 examples\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    print(\"Accuracy:\", accuracy.eval({x: train.values, y: labels}))\n",
    "    \n",
    "    # Prediction\n",
    "    classification = sess.run(pred, feed_dict={x: test.values})\n",
    "    print(classification)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = np.argmax(classification, 1)\n",
    "df = DataFrame({'Label': result}, index=range(1, len(result)+1))\n",
    "df.index.name='ImageId'\n",
    "df.to_csv('result.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
